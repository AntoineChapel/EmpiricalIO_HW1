{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "from IPython.display import display, Latex\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.71]\n",
      " [ 0.44]\n",
      " [-1.37]\n",
      " [-0.91]\n",
      " [-1.23]\n",
      " [ 1.  ]] \n",
      "\n",
      "[[3.22 0.   0.   0.   0.   0.  ]\n",
      " [0.   3.24 0.   0.   0.   0.  ]\n",
      " [0.   0.   2.87 0.   0.   0.  ]\n",
      " [0.   0.   0.   4.15 0.   0.  ]\n",
      " [0.   0.   0.   0.   1.38 0.  ]\n",
      " [0.   0.   0.   0.   0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "N = 1000\n",
    "J = 4\n",
    "T = 150\n",
    "\n",
    "# Generate the data\n",
    "np.random.seed(123)\n",
    "mu = np.array([-1.71, 0.44, -1.37, -0.91, -1.23, 1]).reshape(-1, 1)\n",
    "sigma = np.diag(np.array([3.22, 3.24, 2.87, 4.15, 1.38, 1])).reshape(6, 6)\n",
    "\n",
    "print(mu, '\\n')\n",
    "print(sigma)\n",
    "\n",
    "\n",
    "# generate the random parameters\n",
    "betas = np.random.multivariate_normal(mu.flatten(), sigma, N)\n",
    "betas_np = betas[:, :-2]\n",
    "etas_np = betas[:, -2]\n",
    "gammas_np = betas[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_transition_states = pd.read_csv(r'price_transition_states.csv')\n",
    "price_transition_matrix = pd.read_csv(r'transition_prob_matrix.csv')\n",
    "price_transition_matrix_np = price_transition_matrix.to_numpy()\n",
    "price_transition_states_np = price_transition_states.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prices(states, transition, T):\n",
    "    state_indices = np.arange(states.shape[0])\n",
    "\n",
    "    price_simu = np.zeros((T, 6)) #create a matrix to store the simulated prices\n",
    "    price_simu[0] = states[0] #fix the initial vector of prices\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        preceding_state = price_simu[t-1, :] #take the preceding state\n",
    "        index_preceding_state = int(preceding_state[-1] - 1) #take the index of the preceding state (-1 for 0-indexing in Python)\n",
    "        index_next_state = np.random.choice(state_indices, p=(transition[index_preceding_state, :].flatten())) #draw the next state\n",
    "        price_simu[t, :] = states[index_next_state] #update the price vector and store it\n",
    "    return price_simu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_150_by_6 = simulate_prices(price_transition_states_np, price_transition_matrix_np, T)\n",
    "prices_150_by_4 = price_150_by_6[:, :-2] #remove the indices column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate baseline utility data (no loyalty)\n",
    "utility_np = np.zeros((T, 1+J, N)) # 1 for the outside option, J for the number of products\n",
    "for t in range(1, T):\n",
    "    for i in range(N):\n",
    "        utility_np[t, 0, i] = np.random.gumbel() #outside option, just a random noise\n",
    "        utility_np[t, 1:, i] = betas_np[i, :] + etas_np[i]*prices_150_by_4[t, :] + np.random.gumbel(size=J) #utility for the J products\n",
    "\n",
    "#utility_np_orig = utility_np.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add loyalty\n",
    "state_matrix = np.zeros((T, N), dtype=int) #the state at time 0 is 0\n",
    "state_matrix[1, :] = np.argmax(utility_np[0, :, :], axis=0) #initialize the state simulation\n",
    "\n",
    "for t in range(1, T-1):\n",
    "    for i in range(N):\n",
    "        state_it = state_matrix[t, i]\n",
    "        for j in range(1, J+1): #exclude the outside option\n",
    "            utility_np[t, j, i] += gammas_np[i] * (j == state_it)\n",
    "        choice = np.argmax(utility_np[t, :, i])\n",
    "        if choice==0:\n",
    "            state_matrix[t+1, i] = state_it ### if the outside option is chosen, the state remains the same\n",
    "        else:\n",
    "            state_matrix[t+1, i] = choice ### if a product is chosen, the state is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility_orig_jnp = jnp.array(utility_np_orig[100:, :, :])  #50 x 5 x 1000\n",
    "utility_jnp = jnp.array(utility_np[100:, :, :])            #50 x 5 x 1000\n",
    "choice_jnp = jnp.argmax(utility_np, axis=1)[100:, :]       #50 x 1000\n",
    "prices_50_by_4_jnp = jnp.array(prices_150_by_4[100:, :])   #50 x 4\n",
    "state_matrix_jnp = jnp.array(state_matrix[100:, :])        #50 x 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def ccp(theta):\n",
    "    \"\"\"\n",
    "    Compute the choice probabilities for each time period and product for a given theta, for each possible state\n",
    "    There are 4 possible states (individuals are never in state 0). For a given theta, compute the choice probabilities for each state\n",
    "    Should a return a (T, J, J+1) array. That is, for each period, for each possible state, the choice probas\n",
    "    \"\"\"\n",
    "    theta_jnp = jnp.array(theta).flatten()\n",
    "    betas = theta_jnp[:-2]\n",
    "    eta = theta_jnp[-2]\n",
    "    gamma = theta_jnp[-1]\n",
    "    \n",
    "    #possible states: 0, 1, 2, 3, 4 \n",
    "    v_1to4_utility_state0 = (betas + eta * prices_50_by_4_jnp).reshape(50, 1, 4)\n",
    "    v_1to4_utility_state1to4 = (betas + eta * prices_50_by_4_jnp).reshape(50, 1, 4) + gamma * jnp.eye(4)\n",
    "    v_utility = jnp.concatenate((v_1to4_utility_state0, v_1to4_utility_state1to4), axis=1)\n",
    "    v_default = jnp.zeros((50, 5, 1))\n",
    "    v_utility_full = jnp.concatenate((v_default, v_utility), axis=2)\n",
    "\n",
    "    # Compute choice probabilities \n",
    "    log_sumexps = logsumexp(v_utility_full, axis=2, keepdims=True)\n",
    "    probas = jnp.exp(v_utility - log_sumexps) #get the choice probabilities for each time period and product\n",
    "\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def likelihood(theta): #(log)-likelihood function\n",
    "    probas_theta = ccp(theta) #get the choice probabilities for the candidate theta\n",
    "    log_likelihood = jnp.sum(jnp.log(probas_theta[jnp.arange(50)[:, None], state_matrix_jnp, choice_jnp])) #sum the log-probabilities of the observed choices\n",
    "    return -log_likelihood\n",
    "\n",
    "grad_likelihood = jit(grad(likelihood)) ## gradient of the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_adam(f, grad_f, x0, norm=1e9, tol=0.1, lr=0.05, maxiter=1000, verbose=0, *args): ## generic adam optimizer\n",
    "  \"\"\"\n",
    "  Generic Adam Optimizer. Specify a function f, a starting point x0, possibly a \\n\n",
    "  learning rate in (0, 1). The lower the learning rate, the more stable (and slow) the convergence.\n",
    "  \"\"\"\n",
    "  tic = time.time()\n",
    "  solver = optax.adam(learning_rate=lr)\n",
    "  params = jnp.array(x0, dtype=jnp.float32)\n",
    "  opt_state = solver.init(params)\n",
    "  iternum = 0\n",
    "  while norm > tol and iternum < maxiter :\n",
    "    iternum += 1\n",
    "    grad = grad_f(params, *args)\n",
    "    updates, opt_state = solver.update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    params = jnp.asarray(params, dtype=jnp.float32)\n",
    "    norm = jnp.max(jnp.abs(grad))\n",
    "    if verbose > 0:\n",
    "      if iternum % 100 == 0:\n",
    "        print(f\"Iteration: {iternum}  Norm: {norm}  theta: {jnp.round(params, 2)}\")\n",
    "    if verbose > 1:\n",
    "      print(f\"Iteration: {iternum}  Norm: {norm}  theta: {jnp.round(params, 2)}\")\n",
    "  tac = time.time()\n",
    "  if iternum == maxiter:\n",
    "    print(f\"Convergence not reached after {iternum} iterations. \\nTime: {tac-tic} seconds. Norm: {norm}\")\n",
    "  else:\n",
    "    print(f\"Convergence reached after {iternum} iterations. \\nTime: {tac-tic} seconds. Norm: {norm}\")\n",
    "\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100  Norm: 219.14144897460938  theta: [ 3.09        0.53999996  2.37        0.62        0.68       -0.47      ]\n",
      "Iteration: 200  Norm: 136.03036499023438  theta: [ 3.6         1.3         2.87        1.41        0.52       -0.48999998]\n",
      "Iteration: 300  Norm: 101.1019287109375  theta: [ 4.0699997   2.03        3.34        2.1699998   0.35999998 -0.48999998]\n",
      "Iteration: 400  Norm: 76.05815887451172  theta: [ 4.5099998   2.6499999   3.77        2.81        0.25       -0.48999998]\n",
      "Iteration: 500  Norm: 57.647735595703125  theta: [ 4.89        3.1599998   4.15        3.33        0.17999999 -0.48999998]\n",
      "Iteration: 600  Norm: 44.44678497314453  theta: [ 5.23        3.57        4.48        3.74        0.13       -0.48999998]\n",
      "Iteration: 700  Norm: 34.99720764160156  theta: [ 5.52        3.9099998   4.7599998   4.0899997   0.09999999 -0.48999998]\n",
      "Iteration: 800  Norm: 28.120147705078125  theta: [ 5.77  4.2   5.02  4.38  0.07 -0.5 ]\n",
      "Iteration: 900  Norm: 23.02704620361328  theta: [ 5.99  4.45  5.24  4.63  0.06 -0.5 ]\n",
      "Iteration: 1000  Norm: 19.17779541015625  theta: [ 6.2   4.67  5.44  4.85  0.05 -0.5 ]\n",
      "Iteration: 1100  Norm: 16.195144653320312  theta: [ 6.3799996  4.8599997  5.62       5.0499997  0.04      -0.5      ]\n",
      "Iteration: 1200  Norm: 13.8438720703125  theta: [ 6.5499997  5.04       5.79       5.23       0.03      -0.5      ]\n",
      "Iteration: 1300  Norm: 11.969337463378906  theta: [ 6.7   5.2   5.94  5.39  0.03 -0.5 ]\n",
      "Iteration: 1400  Norm: 10.440093994140625  theta: [ 6.8399997  5.35       6.0899997  5.5499997  0.02      -0.5      ]\n",
      "Iteration: 1500  Norm: 9.177520751953125  theta: [ 6.98  5.49  6.22  5.69  0.02 -0.5 ]\n",
      "Iteration: 1600  Norm: 8.130546569824219  theta: [ 7.1        5.62       6.35       5.8199997  0.02      -0.5      ]\n",
      "Iteration: 1700  Norm: 7.239051818847656  theta: [ 7.22  5.75  6.47  5.94  0.01 -0.5 ]\n",
      "Iteration: 1800  Norm: 6.493766784667969  theta: [ 7.3399997  5.8599997  6.58       6.06       0.01      -0.5      ]\n",
      "Iteration: 1900  Norm: 5.849403381347656  theta: [ 7.44  5.97  6.69  6.17  0.01 -0.5 ]\n",
      "Iteration: 2000  Norm: 5.285118103027344  theta: [ 7.5499997  6.08       6.79       6.27       0.01      -0.5      ]\n",
      "Iteration: 2100  Norm: 4.7945709228515625  theta: [ 7.6499996  6.18       6.89       6.37       0.01      -0.5      ]\n",
      "Iteration: 2200  Norm: 4.368400573730469  theta: [ 7.74       6.2799997  6.99       6.47       0.01      -0.5      ]\n",
      "Iteration: 2300  Norm: 3.988739013671875  theta: [ 7.83       6.37       7.08       6.5699997  0.        -0.5      ]\n",
      "Iteration: 2400  Norm: 3.65069580078125  theta: [ 7.9199996  6.46       7.17       6.66       0.        -0.5      ]\n",
      "Iteration: 2500  Norm: 3.3718185424804688  theta: [ 8.01       6.5499997  7.25       6.74       0.        -0.5      ]\n",
      "Iteration: 2600  Norm: 3.0893096923828125  theta: [ 8.09       6.6299996  7.3399997  6.83       0.        -0.5      ]\n",
      "Iteration: 2700  Norm: 2.8475494384765625  theta: [ 8.17       6.72       7.4199996  6.91       0.        -0.5      ]\n",
      "Iteration: 2800  Norm: 2.6372528076171875  theta: [ 8.25       6.7999997  7.5        6.99       0.        -0.5      ]\n",
      "Iteration: 2900  Norm: 2.4426422119140625  theta: [ 8.33       6.87       7.5699997  7.0699997  0.        -0.5      ]\n",
      "Iteration: 3000  Norm: 2.2615966796875  theta: [ 8.41       6.95       7.6499996  7.1499996 -0.        -0.5      ]\n",
      "Iteration: 3100  Norm: 2.0921707153320312  theta: [ 8.48  7.02  7.72  7.22 -0.   -0.5 ]\n",
      "Iteration: 3200  Norm: 1.9641036987304688  theta: [ 8.55       7.1        7.7999997  7.29      -0.        -0.5      ]\n",
      "Iteration: 3300  Norm: 1.8397979736328125  theta: [ 8.62  7.17  7.87  7.37 -0.   -0.5 ]\n",
      "Iteration: 3400  Norm: 1.7128143310546875  theta: [ 8.69  7.24  7.94  7.44 -0.   -0.5 ]\n",
      "Iteration: 3500  Norm: 1.5866928100585938  theta: [ 8.76  7.31  8.01  7.5  -0.   -0.5 ]\n",
      "Iteration: 3600  Norm: 1.4904937744140625  theta: [ 8.83       7.3799996  8.07       7.5699997 -0.        -0.5      ]\n",
      "Iteration: 3700  Norm: 1.4023284912109375  theta: [ 8.9       7.44      8.139999  7.64     -0.       -0.5     ]\n",
      "Iteration: 3800  Norm: 1.3115081787109375  theta: [ 8.96       7.5099998  8.21       7.71      -0.        -0.5      ]\n",
      "Iteration: 3900  Norm: 1.2330474853515625  theta: [ 9.03       7.58       8.2699995  7.77      -0.        -0.5      ]\n",
      "Iteration: 4000  Norm: 1.1638946533203125  theta: [ 9.09       7.64       8.33       7.8399997 -0.        -0.5      ]\n",
      "Iteration: 4100  Norm: 1.0782623291015625  theta: [ 9.15       7.7        8.4        7.8999996 -0.        -0.5      ]\n",
      "Iteration: 4200  Norm: 1.023345947265625  theta: [ 9.22  7.77  8.46  7.96 -0.   -0.5 ]\n",
      "Iteration: 4300  Norm: 0.9743194580078125  theta: [ 9.28       7.83       8.5199995  8.0199995 -0.        -0.5      ]\n",
      "Iteration: 4400  Norm: 0.8935546875  theta: [ 9.34  7.89  8.58  8.08 -0.   -0.5 ]\n",
      "Iteration: 4500  Norm: 0.8270416259765625  theta: [ 9.4       7.95      8.639999  8.15     -0.       -0.5     ]\n",
      "Iteration: 4600  Norm: 0.810272216796875  theta: [ 9.46  8.01  8.7   8.21 -0.   -0.5 ]\n",
      "Iteration: 4700  Norm: 0.759613037109375  theta: [ 9.5199995  8.07       8.76       8.26      -0.        -0.5      ]\n",
      "Iteration: 4800  Norm: 0.6989898681640625  theta: [ 9.58  8.13  8.82  8.32 -0.   -0.5 ]\n",
      "Iteration: 4900  Norm: 0.646209716796875  theta: [ 9.639999  8.19      8.88      8.38     -0.       -0.5     ]\n",
      "Iteration: 5000  Norm: 0.621795654296875  theta: [ 9.69  8.24  8.94  8.44 -0.   -0.5 ]\n",
      "Convergence not reached after 5000 iterations. \n",
      "Time: 60.51659035682678 seconds. Norm: 0.621795654296875\n"
     ]
    }
   ],
   "source": [
    "theta_MLE_homo = minimize_adam(likelihood, grad_likelihood, jnp.ones(6), lr=0.1, verbose=1, maxiter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.4085059 ,  0.8921241 , -0.77546567, -0.9602101 , -1.160281  ,\n",
       "       -0.58544415], dtype=float32)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_MLE_homo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EIO_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
